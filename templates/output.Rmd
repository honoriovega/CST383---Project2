---
title: "Analysis of Video Game Sales Prediction"
author: "Honorio Vega, Andrew Sanchez, Bret Stine"
date: "May 3, 2018"
output: html_document
---
```{r global_options, include=TRUE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
library(rpart)
library(rpart.plot)
library(maptree)
source("https://raw.githubusercontent.com/grbruns/cst383/master/lin-regr-util.R")
# perform n-fold cross-validation on the given data set; return mean rmse
# dat - a data frame
# y - response variable, as a string
# xs - predictor variables, as a vector of strings
# n   - the 'n' in n-fold cross-validation
cross_validate_lm = function(dat, y, xs, n=10) {
  # create the formula to be used with lm
  ff = reformulate(xs, y)
  
  # compute indexes of the groups
  k = nrow(dat)  
  dat1 = dat[sample(1:k),]     # shuffle the data
  starts = seq(1, k, by=floor(k/n))[1:n]
  ends = c(starts[2:n]-1, k)
  
  sum_rmse = 0
  for (i in 1:n) {
    tests = starts[i]:ends[i]
    fit = lm(ff, data=dat1[-tests,])
    if (length(fit$coefficients) > fit$rank) {
      print(paste0("rank-deficit problem with ", ff))
    }
    predicted = predict(fit, newdata=dat1[tests,])
    actual = dat1[tests,y]
    rmse = sqrt(mean((actual-predicted)^2))
    sum_rmse = sum_rmse + rmse
    # print(paste0(i,": RMSE = ",rmse))
  }
  return(sum_rmse/n)
}
```

### Goal/Hypothesis
Our team's goal is to predict global video game sales based off of data collected in the past 15 years. 

### Introduction
The data set is based off of video game sales as of January 2017. Origin of the data can be found using the link provided:  https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings. We decided to use this data set because of each member has an attachment to video games. Being able to predict future video game sales would be valuable to consumers and companies. 

### Read & Preprocessing
We read the data in and begin preprocessing. First thing we do is get the total number of NAs values and see that there is 37396 rows of missing data. In order to keep our data recent and relevent we decided to use complete cases. Since many of the games with a year of release lower than 2000s tended to have missing data such as global sales, critic score, and user score. We also scale user score from 0-100 that way it will resemble critics score scaling.

```{r }
setwd('..')
dat = read.csv(paste0(getwd(),"/data/Video_Game_Sales_as_of_Jan_2017.csv"))
names(dat) = tolower(names(dat))

# NAs
sum(is.na(dat))

# Remove any rows with missing data
dat = dat[complete.cases(dat),]

# throw away rows with year less than 2000
dat = dat[as.numeric(as.character(dat$year_of_release)) >= 2000,]
# Scaling user score to 0-100
dat$user_score = dat$user_score*10
```

The data set contains 17416 rows of data with a majority of games being released between 2000s and above.

```{r}
set.seed(123)
before = nrow(dat)
before

par(mar=c(3,7,1,1))
barplot(table(dat$year_of_release), horiz=T, col="RED", las=1)
```

After using complete cases we retain 41% of our data that is recent and relevant to our prediction of global sales. 

```{r}
dat = dat[complete.cases(dat),]
after = nrow(dat)
after/before

```

### Average Sales by Genres
We see that Misc is that top selling genre with mean sales of 1.06 globally. Genres like shooters and platform come in second with a mean sales of 0.92 globally.
```{r}
topGenres = aggregate(cbind(global_sales, na_sales, jp_sales, eu_sales) ~ genre, data=dat, function(x) mean(x))
topGenres = topGenres[order(-topGenres$global_sales),]
head(topGenres, 10)
```

### Highest Sales by Platform
We see in this data set that PS2 has highest sum of sales of all platforms. While X360 and PS3 come in second and third respectively. It is suprising to see PS2 have the highest sum of sales considering it was relased in March of 2000. 
```{r}
topPlatforms = aggregate(cbind(global_sales, na_sales, jp_sales, eu_sales) ~ platform, data=dat, function(x) sum(x))
topPlatforms = topPlatforms[order(-topPlatforms$global_sales),]
head(topPlatforms, 10)
```


### Critic Scores lead to Higher Global Sales?
From our plot we see that games that achieved a critic score greater than 50 tended to have higher global sales. While majority of games that didn't achieve sales of 1 Million are distributed between 20-100 on critic score.
```{r}
plot(global_sales[global_sales>1] ~ critic_score[global_sales>1], data=dat, col="RED", pch=20, xlab="Critic Score", ylab="Sales", main="Critic Score by Global Sales")
points(global_sales[global_sales<1] ~ critic_score[global_sales<1], data=dat, col="NAVY", pch=20)
```

### Cumlative Distribution of Critic Score 
We see that from curve from the plot that the
```{r}
plot(ecdf(dat$critic_score), col="RED", main="Critic Score")
```

### Critic Scores vs User Scores
We see overall user scores are generally higher than critics scores. User scores are usually based off their experiences and impressions of a game, while critic scores are generally follow baselines of how to score a game. 
```{r}
par(mfrow=c(1,2))
# Critic Score
plot(critic_score ~ genre, data=dat, main="Critic Score by Genre", xlab="Genre", ylab="Critic Score", col="RED")
# User Score
plot(user_score ~ genre, data=dat, main="User Score by Genre", xlab="Genre", ylab="User Score", col="RED")
```

### Differences Between Critics and Users
Here we get a closer view of critic and user scores and see for the most part there is small deviation. User scores tend to be higher per genre than their counter part critic scores.
```{r}
agg = aggregate(cbind(critic_score, user_score) ~ genre, data=dat, function(x) mean(x))
plot(agg$critic_score, agg$user_score, xlim=c(65,75), ylab="User Score", xlab="Critic Score", pch=20, main="Critics Score vs User Score")
text(agg$critic_score, agg$user_score, labels=agg$genre, pos=4, col="RED")
```

### Sampling & Splitting
We sample from the data and create training and test data sets with a 70/30 split respectively.
```{r}
# 
set.seed(123)

split = split_data(dat, c(4,1))
tr_dat = split[[1]]
te_dat = split[[2]]
```

### Linear Regression (Model 1)
Linear regression model built from the features of critic score and user score. From our summary we see that critic score and user score of ***, this in turn means they have strong relationship to global sales.
```{r}
fit = lm(global_sales ~ critic_score + user_score, data=tr_dat)
summary(fit)
```

```{r}
# Plot
predicted = predict(fit, newdata=te_dat)
actual = te_dat$global_sales
plot_predict_actual(predicted, actual, 1, "Actual vs Predicted Global Sales")
```

```{r}
# Plot
plot(fit$residuals)
plot(fit$model)

```

We then test our linear regression model by computing the root mean squared error(RMSE). With RMSE the lower the value the better, with our model we achieved a RMSE value of 1.71
```{r}
lmErrs = actual-predicted
rmse = sqrt(mean((actual-predicted)^2))
rmse
```


### Regression Tree (Model 2)
```{r}
fit = rpart(global_sales ~ genre + platform + user_count, data=tr_dat)
```



```{r}
prp(fit, extra=1, varlen=-10,main="Regression Tree to predict Global Sales", type = 2, tweak = 1.5, box.col="tan")
```



```{r}
predicted = predict(fit, te_dat)
regErrs = te_dat$global_sales - predicted
rmse = sqrt(mean(regErrs^2))
rmse
```



```{r}
plot_predict_actual(predicted, te_dat$global_sales, 2, "regression tree price prediction")
```



```{r}
rmse_cv = cross_validate_lm(te_dat, "global_sales", c("platform", "genre", "user_count"))
rmse_cv
```

### (Model 3)

### Comparison of Models
```{r}
par(mfrow=c(1,3))
hist(lmErrs, col="RED", main="Hist of Linear Regression")
hist(regErrs, col="RED", main="Hist of Regression Tree Model")
```

### Our Conclusion
