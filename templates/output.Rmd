---
title: "Project 2 - Video Game Sales Prediction"
author: "Honorio Vega, Andrew Sanchez, Bret Stine"
date: "May 3, 2018"
output: html_document
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=TRUE)
library(rpart)
library(rpart.plot)
library(maptree)
source("https://raw.githubusercontent.com/grbruns/cst383/master/lin-regr-util.R")
# perform n-fold cross-validation on the given data set; return mean rmse
# dat - a data frame
# y - response variable, as a string
# xs - predictor variables, as a vector of strings
# n   - the 'n' in n-fold cross-validation
cross_validate_lm = function(dat, y, xs, n=10) {
  # create the formula to be used with lm
  ff = reformulate(xs, y)
  
  # compute indexes of the groups
  k = nrow(dat)  
  dat1 = dat[sample(1:k),]     # shuffle the data
  starts = seq(1, k, by=floor(k/n))[1:n]
  ends = c(starts[2:n]-1, k)
  
  sum_rmse = 0
  for (i in 1:n) {
    tests = starts[i]:ends[i]
    fit = lm(ff, data=dat1[-tests,])
    if (length(fit$coefficients) > fit$rank) {
      print(paste0("rank-deficit problem with ", ff))
    }
    predicted = predict(fit, newdata=dat1[tests,])
    actual = dat1[tests,y]
    rmse = sqrt(mean((actual-predicted)^2))
    sum_rmse = sum_rmse + rmse
    # print(paste0(i,": RMSE = ",rmse))
  }
  return(sum_rmse/n)
}
```

### Goal
Our team's goal is to predict global video game sales based off of data collected in the past 15 years. 

### Introduction(Need More)
The dataset comes from Kaggle.com and is a compilation of video games sales along with ratings. 

### Read & Preprocessing
We read the data in and begin preprocessing. First thing we do is get the total number of NAs values and see that there is 37396 rows of missing data. In order to keep our data recent and relevent we decided to use complete cases. Since many of the games with a year of release lower than 2000s tended to have missing data such as global sales, critic score, and user score.

```{r }
setwd('..')
dat = read.csv(paste0(getwd(),"/data/Video_Game_Sales_as_of_Jan_2017.csv"))
names(dat) = tolower(names(dat))

# NAs
sum(is.na(dat))
```

The data set contains 17416 rows of data with a majority of games being released between 2000s and above.

```{r}
set.seed(123)
before = nrow(dat)
before

par(mar=c(3,7,1,1))
barplot(table(dat$year_of_release), horiz=T, col="RED", las=1)
```

After using complete cases we retain 41% of our data that is recent and relevant to our prediction of global sales. 

```{r}
dat = dat[complete.cases(dat),]
after = nrow(dat)
after/before

```

### Average Sales by Genres

```{r}
topGenres = aggregate(cbind(global_sales, na_sales, jp_sales, eu_sales) ~ genre, data=dat, function(x) mean(x))
topGenres = topGenres[order(-topGenres$global_sales),]
head(topGenres, 10)
```

### Highest Sales by Platform
We see in this data set that PS2 has highest sum of sales of all platforms. While X360 and PS3 come in second and third respectively. It is suprising to see PS2 have the highest sum of sales considering it was relased in March of 2000. 
```{r}
topPlatforms = aggregate(cbind(global_sales, na_sales, jp_sales, eu_sales) ~ platform, data=dat, function(x) sum(x))
topPlatforms = topPlatforms[order(-topPlatforms$global_sales),]
head(topPlatforms, 10)
```


### Critic Scores lead to Higher Global Sales?
From our plot we see that games that achieved a critic score greater than 50 tended to have higher global sales. While majority of games that didn't achieve sales of 1 Million are distributed between 20-100 on critic score.
```{r}
plot(global_sales[global_sales>1] ~ critic_score[global_sales>1], data=dat, col="RED", pch=20, xlab="Critic Score", ylab="Sales", main="Critic Score by Global Sales")
points(global_sales[global_sales<1] ~ critic_score[global_sales<1], data=dat, col="NAVY", pch=20)
```

### Cumlative Distribution of Critic Score(?)
```{r}
<<<<<<< HEAD
plot(ecdf(dat$critic_score), col="RED", main="Critic Score")
=======
plot(ecdf(dat$critic_score), col="RED", main="Global Sales")
>>>>>>> 32814010be80dec8826ca90051b054b50c014548
```


### Sampling & Splitting
We sample from the data and create training and test data sets with a 70/30 split respectively.
```{r}
# 
set.seed(123)

#tr_rows = sample(nrow(dat), 0.7 * nrow(dat))
#tr_dat = dat[tr_rows,]
#te_dat = dat[-tr_rows,]
split = split_data(dat, c(4,1))
tr_dat = split[[1]]
te_dat = split[[2]]
```

### Linear Regression (Model 1)
Linear regression model built from the features of user count and user score. From our summary we see that user count and user score of ***, this in turn means they have strong relationship to global sales.
```{r}
fit = lm(global_sales ~ user_count + user_score, data=tr_dat)
summary(fit)
```

```{r}
# Plot
predicted = predict(fit, newdata=te_dat)
actual = te_dat$global_sales
plot_predict_actual(predicted, actual, 1, "Actual vs Predicted Global Sales")
```

We then test our linear regression model by computing the root mean squared error(RMSE). With RMSE the lower the value the better, with our model we achieved a RMSE value of 1.68.
```{r}
lmErrs = actual-predicted
rmse = sqrt(mean((actual-predicted)^2))
rmse
plot(fit)
```

### Learning Curves(Model 1)
```{r}
library(caret)
learningCurve = function(training, test, interval, max) {
  tr_errs = c()
  te_errs = c()
  tr_act = tr_dat$global_sales
  te_act = te_dat$global_sales
  sizes = seq(interval, max, interval)
  for (size in sizes) {
    dat = tr_dat[1:size,]
    fit = lm(global_sales ~ user_score + user_count, data=dat)
    tr_pred = predict(fit)
    te_pred = predict(fit, newdata=te_dat)
    tr_errs = c(tr_errs, 1-mean(tr_pred==tr_act))
    te_errs = c(te_errs, 1-mean(te_pred==te_act))
  }
  plot(sizes, tr_errs, type="b", xlab="Training Size", ylab="Error", col="blue")
  points(sizes, te_errs, type="b", col="RED")
}
learningCurve(tr_dat, te_dat, 100, 1000)
```


### Regression Tree (Model 2)
```{r}
fit = rpart(global_sales ~ genre + platform + user_count, data=tr_dat)
```



```{r}
prp(fit, extra=1, varlen=-10,main="Regression Tree to predict Global Sales", type = 2, tweak = 1.5, box.col="tan")
```



```{r}
predicted = predict(fit, te_dat)
errors = te_dat$global_sales - predicted
rmse = sqrt(mean(errors^2))
rmse
```



```{r}
plot_predict_actual(predicted, te_dat$global_sales, 2, "regression tree price prediction")
```



```{r}
rmse_cv = cross_validate_lm(te_dat, "global_sales", c("platform", "genre", "user_count"))
rmse_cv
```



### (Model 3)

### Comparison of Models

### Our Conclusion
